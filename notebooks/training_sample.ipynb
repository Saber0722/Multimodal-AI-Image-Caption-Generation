{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf2f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rich.console import Console\n",
    "import re\n",
    "\n",
    "console = Console()\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533e6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base paths\n",
    "\n",
    "PROJECT_ROOT = Path(\"../\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"COCO\"\n",
    "\n",
    "TRAIN_IMG_DIR = DATA_DIR / \"train2014\"\n",
    "ANNOTATIONS_DIR = DATA_DIR / \"annotations\"\n",
    "\n",
    "CAPTIONS_TRAIN = ANNOTATIONS_DIR / \"captions_train2014.json\"\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert TRAIN_IMG_DIR.exists()\n",
    "assert CAPTIONS_TRAIN.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da80dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:14:17,784 - INFO - Merge successful.\n"
     ]
    }
   ],
   "source": [
    "# load and merge\n",
    "\n",
    "with open(CAPTIONS_TRAIN) as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "images_df = pd.DataFrame(train_data[\"images\"])\n",
    "annotations_df = pd.DataFrame(train_data[\"annotations\"])\n",
    "\n",
    "df = annotations_df.merge(\n",
    "    images_df[[\"id\", \"file_name\"]],\n",
    "    left_on=\"image_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df[\"image_path\"] = df[\"file_name\"].apply(lambda x: TRAIN_IMG_DIR / x)\n",
    "\n",
    "assert df[\"image_path\"].iloc[0].exists()\n",
    "logger.info(\"Merge successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f4b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean captions\n",
    "\n",
    "def clean_caption(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,']\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df[\"caption\"] = df[\"caption\"].apply(clean_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7141e440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Removed </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">149</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> duplicate image-caption pairs</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mRemoved \u001b[0m\u001b[1;32m149\u001b[0m\u001b[1;32m duplicate image-caption pairs\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove duplicates from same image\n",
    "\n",
    "before = len(df)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"image_id\", \"caption\"])\n",
    "\n",
    "after = len(df)\n",
    "\n",
    "console.print(f\"[bold green]Removed {before - after} duplicate image-caption pairs[/bold green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485dd1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-19 11:14:19,495 - INFO - Dataset size after image existence check: 413964\n"
     ]
    }
   ],
   "source": [
    "# remove missing images\n",
    "\n",
    "df = df[df[\"image_path\"].apply(lambda x: x.exists())]\n",
    "\n",
    "logger.info(f\"Dataset size after image existence check: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48c4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit caption length\n",
    "\n",
    "df[\"caption_length\"] = df[\"caption\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "df = df[df[\"caption_length\"] <= 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb921b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~Save all samples\n",
    "\n",
    "output_path = OUTPUT_DIR / \"coco_full_data.csv\"\n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37b9a413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Subset size:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100011</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSubset size:\u001b[0m \u001b[1;36m100011\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~20k subset\n",
    "\n",
    "unique_images = df[\"image_id\"].unique()\n",
    "\n",
    "np.random.seed(42)\n",
    "selected_images = np.random.choice(unique_images, size=20000, replace=False)\n",
    "\n",
    "subset_df = df[df[\"image_id\"].isin(selected_images)].reset_index(drop=True)\n",
    "\n",
    "console.print(f\"[bold cyan]Subset size:[/bold cyan] {len(subset_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "555cd2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Saved to:</span> <span style=\"color: #800080; text-decoration-color: #800080\">/home/saber/Wox/ANLP/multimodal_ai/data/processed/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">coco_train_20k.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mSaved to:\u001b[0m \u001b[35m/home/saber/Wox/ANLP/multimodal_ai/data/processed/\u001b[0m\u001b[95mcoco_train_20k.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save processed data\n",
    "\n",
    "output_path = OUTPUT_DIR / \"coco_train_20k.csv\"\n",
    "\n",
    "subset_df[[\"image_path\", \"caption\"]].to_csv(output_path, index=False)\n",
    "\n",
    "console.print(f\"[bold yellow]Saved to:[/bold yellow] {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6d9091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Subset size:</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9997</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSubset size:\u001b[0m \u001b[1;36m9997\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~2k val subset\n",
    "\n",
    "# ~20k subset\n",
    "\n",
    "unique_images_val = df[\"image_id\"].unique()\n",
    "\n",
    "np.random.seed(43)\n",
    "selected_images_val = np.random.choice(unique_images_val, size=2000, replace=False)\n",
    "\n",
    "subset_df = df[df[\"image_id\"].isin(selected_images_val)].reset_index(drop=True)\n",
    "\n",
    "console.print(f\"[bold cyan]Subset size:[/bold cyan] {len(subset_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eebf676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Saved to:</span> <span style=\"color: #800080; text-decoration-color: #800080\">/home/saber/Wox/ANLP/multimodal_ai/data/processed/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">coco_val_2k.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mSaved to:\u001b[0m \u001b[35m/home/saber/Wox/ANLP/multimodal_ai/data/processed/\u001b[0m\u001b[95mcoco_val_2k.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save processed data\n",
    "\n",
    "output_path_val = OUTPUT_DIR / \"coco_val_2k.csv\"\n",
    "\n",
    "subset_df[[\"image_path\", \"caption\"]].to_csv(output_path_val, index=False)\n",
    "\n",
    "console.print(f\"[bold yellow]Saved to:[/bold yellow] {output_path_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
